# bics-chatbot

Chatbot em Python para **apontar defeitos em trechos de cÃ³digo** e explicar problemas de forma clara.
Hoje ele combina:

- checagem de sintaxe com `ast.parse` (erros como falta de `:`, parÃªnteses, aspas);
- um **modelo leve de ML local** (TFâ€‘IDF) treinado em um dataset de cÃ³digos Python para medir
  quÃ£o â€œnaturalâ€ Ã© o trecho analisado em relaÃ§Ã£o ao corpus.

## âš™ï¸ InstalaÃ§Ã£o (dev)

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
pre-commit install
```

## ğŸ§ª Rodando testes e lint

```bash
pytest -q
ruff check .
black --check .
```

## ğŸš€ Usando via CLI

```bash
python -m codebug_bot.cli --file examples/broken_missing_colon.py --apply-fix
```

## ğŸ–¥ï¸ Interface grÃ¡fica (GUI)

```bash
python -m codebug_bot.gui
```

- Campo de texto para colar/escrever cÃ³digo.
- BotÃ£o â€œAnalisar cÃ³digoâ€ roda a anÃ¡lise completa (sintaxe + similaridade com dataset).
- Mostra problemas detectados, nÃ­vel de confianÃ§a e exemplos semelhantes vindos do dataset.

## ğŸ§° Como funciona (resumo)

1. Tentamos fazer `ast.parse(code)`. Se houver `SyntaxError`, classificamos a falha em tipos comuns:
   - `missing_colon` (faltou `:` em `def`, `if`, etc.);
   - `missing_parenthesis` (parÃªntese/estrutura nÃ£o fechada);
   - `missing_quotation` (string nÃ£o fechada);
   - `syntax_error` genÃ©rico, quando a mensagem nÃ£o se encaixa bem em nenhum caso acima.
2. Computamos um **score de similaridade** do trecho com um corpus grande de cÃ³digos Python vÃ¡lidos,
   usando um modelo TFâ€‘IDF de nâ€‘gramas de caracteres treinado localmente.
3. Retornamos:
   - `issues`: lista de problemas encontrados, com linha/coluna, mensagem e sugestÃ£o de correÃ§Ã£o;
   - `model_score`: quÃ£o parecido o cÃ³digo Ã© com o dataset;
   - `similar_examples`: alguns trechos reais do dataset mais prÃ³ximos do cÃ³digo analisado.

> Limites: heurÃ­sticas nÃ£o â€œentendemâ€ semÃ¢ntica. Para bugs lÃ³gicos, plugue um LLM em `codebug_bot/llm.py`.

## ğŸ“¦ Dataset (treinamento local)

O script `scripts/prepare_dataset.py` explica como baixar e limpar o dataset
[`iamtarun/python_code_instructions_18k_alpaca`](https://huggingface.co/datasets/iamtarun/python_code_instructions_18k_alpaca)
para gerar um **corpus** local de trechos Python vÃ¡lidos (coluna `output`).
Esse corpus Ã© salvo em `data/corpus/python_outputs.txt` e Ã© usado para:

- treinar o modelo TFâ€‘IDF local na primeira execuÃ§Ã£o;
- calcular o score de similaridade e trazer exemplos parecidos na interface.

## ğŸ¤ Contribuindo

- Veja `CONTRIBUTING.md` e o template de PR. Use uma branch por feature, commits pequenos e descritivos.
- O CI roda lint + testes.

## ğŸ“ LicenÃ§a

MIT.
